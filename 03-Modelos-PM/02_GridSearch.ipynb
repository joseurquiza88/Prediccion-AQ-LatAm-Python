{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcefdae1",
   "metadata": {},
   "source": [
    "#### OBJETIVO: Hacer pruebas de los modelos de ML para seleccionar los hiperparametros a traves del grid Search\n",
    "\n",
    "Comentario: suelen tardar bastante y va a depender de la cantidad de informacion\n",
    "- Pregunta: que paramertos fueron iguales en ambos lenguajes?, similares?, muy diferentes?. Comparar!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "080383f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "librerias ok\n"
     ]
    }
   ],
   "source": [
    "#Librerias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "import joblib\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "print(\"librerias ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910c8165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Mejores parámetros:\n",
      "{'svr__C': 10, 'svr__epsilon': 0.5, 'svr__gamma': 0.1}\n",
      "        R2     RMSE      Bias       min        max\n",
      "0  0.47091  7.72543 -1.044734  2.136073  45.452022\n"
     ]
    }
   ],
   "source": [
    "### -------------- SVR --------------------------\n",
    "# SVR SIEMPRE debe usarse con variables escaladas\n",
    "\n",
    "#Datos de entreada\n",
    "estacion = \"BA\"\n",
    "modelo = \"1\"\n",
    "\n",
    "dir_base = f\"D:/Josefina/Proyectos/ProyectoChile/{estacion}/modelos/ParticionDataSet/\"\n",
    "\n",
    "train_data = pd.read_csv(\n",
    "    f\"{dir_base}/Modelo_{modelo}/M{modelo}_train_{estacion}.csv\"\n",
    ")\n",
    "\n",
    "test_data = pd.read_csv(\n",
    "    f\"{dir_base}/Modelo_{modelo}/M{modelo}_test_{estacion}.csv\"\n",
    ")\n",
    "\n",
    "# Variables ver para cada uno de los sitios\n",
    "features = [\n",
    "    \"AOD_055\", \"ndvi\", \"BCSMASS_dia\", \"DUSMASS_dia\",\n",
    "    \"SO2SMASS_dia\", \"SO4SMASS_dia\", \"SSSMASS_dia\",\n",
    "    \"blh_mean\", \"sp_mean\", \"d2m_mean\",\n",
    "    \"v10_mean\", \"u10_mean\", \"tp_mean\",\n",
    "    \"DEM\", \"dayWeek\"\n",
    "]\n",
    "\n",
    "#Determinar los datos\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[\"PM25\"]\n",
    "\n",
    "X_test = test_data[features]\n",
    "y_test = test_data[\"PM25\"]\n",
    "\n",
    "# Pipeline (escalado + SVR)\n",
    "# Pipeline es una forma de encadenar pasos que se ejecutan siempre en el orden correcto, sin fugas de información (data leakage).\n",
    "\n",
    "# En cada fold:\n",
    "# - El scaler se ajusta solo con el fold de entrenamiento\n",
    "# - Se transforma el fold de validación\n",
    "# - Se entrena el SVR\n",
    "# - Se evalúa\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svr\", SVR(kernel=\"rbf\"))\n",
    "])\n",
    "\n",
    "#Grilla de hiperparametros a evaluar\n",
    "param_grid = {\n",
    "    \"svr__C\": [0.1, 1, 10, 100],\n",
    "    \"svr__epsilon\": [0.01, 0.1, 0.2, 0.5],\n",
    "    \"svr__gamma\": [0.001, 0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "# Grid Search con validación cruzada\n",
    "#Buscar la mejor combinacion de hiperparametros\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"r2\",      # equivalente a optimizar R2\n",
    "    cv=5,              # similar a tune.svm\n",
    "    n_jobs=-1,         # usa todos los núcleos\n",
    "    verbose=2\n",
    ")\n",
    "#Ajustar el modelo\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "#############################\n",
    "#Mejores hiperparametros\n",
    "print(\"Mejores parametros:\")\n",
    "print(grid.best_params_)\n",
    "best_svr = grid.best_estimator_\n",
    "#para BA tardo 2m9\n",
    "\n",
    "#Prediccion para ver las metricas pero no son las del modelo final sino ver los mejores hiperparametrsos\n",
    "y_pred = best_svr.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "bias = np.mean(y_pred - y_test)\n",
    "\n",
    "#Resultaods\n",
    "resultados_SVR = pd.DataFrame({\n",
    "    \"R2\": [r2],\n",
    "    \"RMSE\": [rmse],\n",
    "    \"Bias\": [bias],\n",
    "    \"min\": [y_pred.min()],\n",
    "    \"max\": [y_pred.max()]\n",
    "})\n",
    "\n",
    "print(resultados_SVR)\n",
    "\n",
    "\n",
    "## Guardar modelo\n",
    "# output_dir = f\"D:/Josefina/Proyectos/Tesis/{estacion}/modelos/\"\n",
    "# joblib.dump(best_svr, f\"{output_dir}/01-SVR-M{modelo}-tuned-{estacion}.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9568f3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "Mejores hiperparámetros:\n",
      "{'max_features': 9, 'min_samples_leaf': 1}\n",
      "RMSE CV:\n",
      "7.5984400502757365\n",
      "         R2      RMSE      Bias  Min_Pred   Max_Pred\n",
      "0  0.588821  6.810409  0.429655  4.908413  57.223313\n"
     ]
    }
   ],
   "source": [
    "### -------------- Extra trees --------------------------\n",
    "\n",
    "#Datos de entrada\n",
    "estacion = \"BA\"\n",
    "modelo = \"1\"\n",
    "\n",
    "dir_base = f\"D:/Josefina/Proyectos/ProyectoChile/{estacion}/modelos/ParticionDataSet/\"\n",
    "\n",
    "train_data = pd.read_csv(f\"{dir_base}/Modelo_{modelo}/M{modelo}_train_{estacion}.csv\")\n",
    "test_data  = pd.read_csv(f\"{dir_base}/Modelo_{modelo}/M{modelo}_test_{estacion}.csv\")\n",
    "\n",
    "#Variables\n",
    "features = [\n",
    "    \"AOD_055\", \"ndvi\", \"BCSMASS_dia\", \"DUSMASS_dia\",\n",
    "    \"SO2SMASS_dia\", \"SO4SMASS_dia\", \"SSSMASS_dia\",\n",
    "    \"blh_mean\", \"sp_mean\", \"d2m_mean\",\n",
    "    \"v10_mean\", \"u10_mean\", \"tp_mean\",\n",
    "    \"t2m_mean\", \"DEM\", \"dayWeek\"\n",
    "]\n",
    "\n",
    "#Setear las variables importantes\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[\"PM25\"]\n",
    "\n",
    "X_test = test_data[features]\n",
    "y_test = test_data[\"PM25\"]\n",
    "\n",
    "#Generar modelos\n",
    "et_model = ExtraTreesRegressor(\n",
    "    n_estimators=500,\n",
    "    random_state=123,\n",
    "    n_jobs=-1\n",
    ")\n",
    "#Grilla de hiperparametros a evaluar\n",
    "param_grid = {\n",
    "    \"max_features\": [3, 5, 7, 9],      # mtry\n",
    "    \"min_samples_leaf\": [1, 3, 5, 10]  # min.node.size\n",
    "}\n",
    "\n",
    "#Contruir modelo con los distintos hiperparametros\n",
    "grid_et = GridSearchCV(\n",
    "    estimator=et_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=10,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "#Ajustar los mdoelos\n",
    "grid_et.fit(X_train, y_train)\n",
    "\n",
    "### Ver cuales son los mejores hiperparametros\n",
    "print(\"Mejores hiperparámetros:\")\n",
    "print(grid_et.best_params_)\n",
    "\n",
    "print(\"RMSE CV:\")\n",
    "print(-grid_et.best_score_)\n",
    "\n",
    "best_et = grid_et.best_estimator_\n",
    "\n",
    "y_pred = best_et.predict(X_test)\n",
    "\n",
    "# Quitar negativos si aparecen (tiene  o no?)\n",
    "mask = y_pred > 0\n",
    "y_pred = y_pred[mask]\n",
    "y_test_f = y_test[mask]\n",
    "#Metricas obtenidas\n",
    "r2 = r2_score(y_test_f, y_pred)\n",
    "rmse = root_mean_squared_error(y_test_f, y_pred)\n",
    "bias = np.mean(y_pred - y_test_f)\n",
    "\n",
    "resultados_ET = pd.DataFrame({\n",
    "    \"R2\": [r2],\n",
    "    \"RMSE\": [rmse],\n",
    "    \"Bias\": [bias],\n",
    "    \"Min_Pred\": [y_pred.min()],\n",
    "    \"Max_Pred\": [y_pred.max()]\n",
    "})\n",
    "#Resultados\n",
    "print(resultados_ET)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# joblib.dump(\n",
    "#     best_et,\n",
    "#     f\"D:/Josefina/Proyectos/Tesis/{estacion}/modelos/01-ET-M{modelo}-tuned-{estacion}.joblib\"\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528f3fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Mejores hiperparámetros:\n",
      "{'max_features': 3}\n",
      "RMSE CV:\n",
      "8.373721419788936\n",
      "         R2      RMSE      Bias  Min_Pred  Max_Pred\n",
      "0  0.560002  7.045036  0.222213   5.51161  53.56604\n",
      "        Variable  Importancia\n",
      "5   SO2SMASS_dia     0.170333\n",
      "2    BCSMASS_dia     0.145680\n",
      "8       blh_mean     0.086662\n",
      "7    SSSMASS_dia     0.070146\n",
      "4       t2m_mean     0.068570\n",
      "11      u10_mean     0.062915\n",
      "9       d2m_mean     0.057347\n",
      "10      v10_mean     0.056743\n",
      "13           DEM     0.051621\n",
      "1           ndvi     0.049473\n",
      "3    DUSMASS_dia     0.044418\n",
      "6   SO4SMASS_dia     0.043721\n",
      "0        AOD_055     0.041275\n",
      "12       tp_mean     0.027314\n",
      "14       dayWeek     0.023783\n"
     ]
    }
   ],
   "source": [
    "## -------------- RANDOM FOREST --------------------------\n",
    "\n",
    "#Datos de entrada\n",
    "estacion = \"BA\"\n",
    "modelo = \"1\"\n",
    "\n",
    "dir_base = f\"D:/Josefina/Proyectos/ProyectoChile/{estacion}/modelos/ParticionDataSet/\"\n",
    "\n",
    "train_data = pd.read_csv(f\"{dir_base}/Modelo_{modelo}/M{modelo}_train_{estacion}.csv\")\n",
    "test_data  = pd.read_csv(f\"{dir_base}/Modelo_{modelo}/M{modelo}_test_{estacion}.csv\")\n",
    "# Variables que dependen del sitio\n",
    "features = [\n",
    "    \"AOD_055\", \"ndvi\", \"BCSMASS_dia\", \"DUSMASS_dia\", \"t2m_mean\",\n",
    "    \"SO2SMASS_dia\", \"SO4SMASS_dia\", \"SSSMASS_dia\", \"blh_mean\",\n",
    "    \"d2m_mean\", \"v10_mean\", \"u10_mean\", \"tp_mean\", \"DEM\", \"dayWeek\"\n",
    "]\n",
    "\n",
    "#Setear las variables de cada dataset\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[\"PM25\"]\n",
    "\n",
    "X_test = test_data[features]\n",
    "y_test = test_data[\"PM25\"]\n",
    "\n",
    "#Construir modelo\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    random_state=123,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "#Grid para evaluar distintos hiperparametros del modelo\n",
    "param_grid = {\n",
    "    \"max_features\": [3, 5, 7, 9]   # unico hiperparametro a evaluar por ahora: mtry \n",
    "}\n",
    "\n",
    "#Se evalua con el cv\n",
    "grid_rf = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "# Se entrena el modelo\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "#Resultados\n",
    "print(\"Mejores hiperparámetros:\")\n",
    "print(grid_rf.best_params_)\n",
    "\n",
    "print(\"RMSE CV:\")\n",
    "print(-grid_rf.best_score_)\n",
    "\n",
    "best_rf = grid_rf.best_estimator_\n",
    "\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# eliminar predicciones negativas\n",
    "mask = y_pred > 0\n",
    "y_pred = y_pred[mask]\n",
    "y_test_f = y_test[mask]\n",
    "\n",
    "r2 = r2_score(y_test_f, y_pred)\n",
    "rmse = root_mean_squared_error(y_test_f, y_pred)\n",
    "bias = np.mean(y_pred - y_test_f)\n",
    "\n",
    "resultados_RF = pd.DataFrame({\n",
    "    \"R2\": [r2],\n",
    "    \"RMSE\": [rmse],\n",
    "    \"Bias\": [bias],\n",
    "    \"Min_Pred\": [y_pred.min()],\n",
    "    \"Max_Pred\": [y_pred.max()]\n",
    "})\n",
    "\n",
    "print(resultados_RF)\n",
    "\n",
    "importances = pd.DataFrame({\n",
    "    \"Variable\": features,\n",
    "    \"Importancia\": best_rf.feature_importances_\n",
    "}).sort_values(\"Importancia\", ascending=False)\n",
    "\n",
    "print(importances)\n",
    "\n",
    "#Para BA termino 1.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d44d9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Mejores hiperparámetros:\n",
      "{'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 600, 'subsample': 0.8}\n",
      "RMSE: 6.81\n",
      "R²: 0.588\n"
     ]
    }
   ],
   "source": [
    "## -------------- XGB --------------------------\n",
    "\n",
    "#Datos de entrada\n",
    "# Paths\n",
    "estacion = \"BA\"\n",
    "modelo = \"1\"\n",
    "base_dir = f\"D:/Josefina/Proyectos/ProyectoChile/{estacion}/modelos/ParticionDataSet/Modelo_{modelo}/\"\n",
    "\n",
    "train_data = pd.read_csv(f\"{base_dir}M{modelo}_train_{estacion}.csv\")\n",
    "test_data  = pd.read_csv(f\"{base_dir}M{modelo}_test_{estacion}.csv\")\n",
    "\n",
    "# Variable objetivo\n",
    "y_train = train_data[\"PM25\"]\n",
    "y_test  = test_data[\"PM25\"]\n",
    "\n",
    "# Predictoras\n",
    "features = [\n",
    "    \"AOD_055\",\"ndvi\",\"BCSMASS_dia\",\"DUSMASS_dia\",\n",
    "    \"SO2SMASS_dia\",\"SO4SMASS_dia\",\"SSSMASS_dia\",\n",
    "    \"blh_mean\",\"sp_mean\",\"d2m_mean\",\"v10_mean\",\n",
    "    \"u10_mean\",\"tp_mean\",\"t2m_mean\",\"DEM\",\"dayWeek\"\n",
    "]\n",
    "#Dataset\n",
    "X_train = train_data[features]\n",
    "X_test  = test_data[features]\n",
    "\n",
    "#Cross validation\n",
    "cv = KFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "#Construir modelo\n",
    "xgb_model = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=123,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "#Original\n",
    "# param_grid_xgb = {\n",
    "#     \"n_estimators\": [500, 1000, 1500],   # nrounds\n",
    "#     \"max_depth\": [3, 6, 9],\n",
    "#     \"learning_rate\": [0.01, 0.1, 0.3],  # eta\n",
    "#     \"gamma\": [0, 1, 5],\n",
    "#     \"colsample_bytree\": [0.6, 0.8, 1],\n",
    "#     \"min_child_weight\": [1, 3, 5],\n",
    "#     \"subsample\": [0.6, 0.8, 1]\n",
    "# }\n",
    "param_grid_xgb = {\n",
    "    \"n_estimators\": [300, 600],\n",
    "    \"max_depth\": [3, 6],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0]\n",
    "}\n",
    "\n",
    "#Probar los hiperparametros\n",
    "grid_xgb = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid_xgb,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=cv,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "#Ajustar modelo\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "\n",
    "#Resultados\n",
    "print(\"Mejores hiperparámetros:\")\n",
    "print(grid_xgb.best_params_)\n",
    "\n",
    "\n",
    "xgb_final = grid_xgb.best_estimator_\n",
    "\n",
    "y_pred = xgb_final.predict(X_test)\n",
    "\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R²: {r2:.3f}\")\n",
    "#Para BA 1.39 ardo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
